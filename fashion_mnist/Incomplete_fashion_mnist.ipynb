{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 4us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 91s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 6us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 19s 4us/step\n",
      "x_train shape:  (60000, 28, 28) y_train shape:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(\"x_train shape: \", x_train.shape, \"y_train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2230c691e08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 23:20:54.265166  4480 deprecation.py:506] From c:\\installs\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu',input_shape(28,28,1)))\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "# model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-25c2f6b57118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\installs\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\installs\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2651\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\installs\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    374\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
