{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall use the ImageDataGenerator class to feed in the training and validation data to the model. This class can also be used to generate augmented data.\n",
    "\n",
    "To know more about ImageDataGenerator class, visit https://keras.io/preprocessing/image/#imagedatagenerator-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagenerator = train_datagenerator.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(128,128),\n",
    "    batch_size=40,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_datagenerator = test_datagenerator.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(128,128),\n",
    "    batch_size=10,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will have 3 Convolution2D layers. You can increse or decrease as per your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3),padding='same', activation='relu', input_shape=(128,128,3)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2),2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2),2),     \n",
    "     \n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2),2),   \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 16,871,489\n",
      "Trainable params: 16,871,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall use Adam optimizer with a learning rate of 0.001 (hyperparameter). We choose 'binary_crossentropy' loss as our model is a binary calssifier (i.e, we have only 2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of each epoch we can check if the model has reached the required accuracy and terminate the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_ACCURACY = 0.85\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if((logs.get('acc')>DESIRED_ACCURACY) and (logs.get('val_acc')>DESIRED_ACCURACY )):\n",
    "      print(\"\\nReached 85% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know more about fit_generator visit https://keras.io/models/model/#fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6918 - acc: 0.6000 - val_loss: 1.4510 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.0046 - acc: 0.5000 - val_loss: 1.3116 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.3999 - acc: 0.5000 - val_loss: 0.7607 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7762 - acc: 0.5000 - val_loss: 0.6825 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6200 - acc: 0.5000 - val_loss: 0.6941 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5829 - acc: 0.9500 - val_loss: 0.6923 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5522 - acc: 0.8250 - val_loss: 0.6907 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5020 - acc: 0.9250 - val_loss: 0.7195 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4240 - acc: 0.9250 - val_loss: 0.7917 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3538 - acc: 0.9000 - val_loss: 0.7737 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3038 - acc: 0.9500 - val_loss: 0.9341 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2588 - acc: 0.9000 - val_loss: 0.7766 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1948 - acc: 0.9750 - val_loss: 0.7346 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1444 - acc: 0.9750 - val_loss: 0.7537 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1090 - acc: 0.9750 - val_loss: 0.6732 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0738 - acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.7017 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7407 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.8127 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.1031 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 7.6768e-04 - acc: 1.0000 - val_loss: 1.2926 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.1004e-04 - acc: 1.0000 - val_loss: 1.4849 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.7971e-04 - acc: 1.0000 - val_loss: 1.6739 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.1651e-04 - acc: 1.0000 - val_loss: 1.8551 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.7435e-04 - acc: 1.0000 - val_loss: 2.0233 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.4034e-04 - acc: 1.0000 - val_loss: 2.1819 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.1059e-04 - acc: 1.0000 - val_loss: 2.3299 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 8.4688e-05 - acc: 1.0000 - val_loss: 2.4676 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 6.3548e-05 - acc: 1.0000 - val_loss: 2.5944 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.6959e-05 - acc: 1.0000 - val_loss: 2.7117 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.4363e-05 - acc: 1.0000 - val_loss: 2.8200 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.5024e-05 - acc: 1.0000 - val_loss: 2.9192 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.8240e-05 - acc: 1.0000 - val_loss: 3.0097 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.3323e-05 - acc: 1.0000 - val_loss: 3.0928 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 9.7901e-06 - acc: 1.0000 - val_loss: 3.1690 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 7.2684e-06 - acc: 1.0000 - val_loss: 3.2390 - val_acc: 0.8000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 5.4573e-06 - acc: 1.0000 - val_loss: 3.3030 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 4.1469e-06 - acc: 1.0000 - val_loss: 3.3617 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.1963e-06 - acc: 1.0000 - val_loss: 3.4152 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.5082e-06 - acc: 1.0000 - val_loss: 3.4644 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.0038e-06 - acc: 1.0000 - val_loss: 3.5097 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.6292e-06 - acc: 1.0000 - val_loss: 3.5511 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.3496e-06 - acc: 1.0000 - val_loss: 3.5892 - val_acc: 0.8000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.1373e-06 - acc: 1.0000 - val_loss: 3.6241 - val_acc: 0.8000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 9.7710e-07 - acc: 1.0000 - val_loss: 3.6562 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 8.5361e-07 - acc: 1.0000 - val_loss: 3.6858 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 7.5761e-07 - acc: 1.0000 - val_loss: 3.7130 - val_acc: 0.8000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.8220e-07 - acc: 1.0000 - val_loss: 3.7381 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 6.2268e-07 - acc: 1.0000 - val_loss: 3.7611 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 5.7520e-07 - acc: 1.0000 - val_loss: 3.7823 - val_acc: 0.8000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 5.3705e-07 - acc: 1.0000 - val_loss: 3.8017 - val_acc: 0.8000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 5.0622e-07 - acc: 1.0000 - val_loss: 3.8194 - val_acc: 0.8000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.8103e-07 - acc: 1.0000 - val_loss: 3.8358 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.6035e-07 - acc: 1.0000 - val_loss: 3.8507 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 4.4318e-07 - acc: 1.0000 - val_loss: 3.8644 - val_acc: 0.8000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 4.2881e-07 - acc: 1.0000 - val_loss: 3.8770 - val_acc: 0.8000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 4.1667e-07 - acc: 1.0000 - val_loss: 3.8885 - val_acc: 0.8000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.0631e-07 - acc: 1.0000 - val_loss: 3.8990 - val_acc: 0.8000\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step - loss: 3.9736e-07 - acc: 1.0000 - val_loss: 3.9085 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 3.8953e-07 - acc: 1.0000 - val_loss: 3.9172 - val_acc: 0.8000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.8259e-07 - acc: 1.0000 - val_loss: 3.9251 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.7635e-07 - acc: 1.0000 - val_loss: 3.9322 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.7066e-07 - acc: 1.0000 - val_loss: 3.9387 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.6540e-07 - acc: 1.0000 - val_loss: 3.9446 - val_acc: 0.8000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.6049e-07 - acc: 1.0000 - val_loss: 3.9499 - val_acc: 0.8000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.5586e-07 - acc: 1.0000 - val_loss: 3.9548 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.5145e-07 - acc: 1.0000 - val_loss: 3.9591 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 3.4721e-07 - acc: 1.0000 - val_loss: 3.9630 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.4312e-07 - acc: 1.0000 - val_loss: 3.9665 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.3916e-07 - acc: 1.0000 - val_loss: 3.9697 - val_acc: 0.8000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.3531e-07 - acc: 1.0000 - val_loss: 3.9725 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.3155e-07 - acc: 1.0000 - val_loss: 3.9750 - val_acc: 0.8000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.2789e-07 - acc: 1.0000 - val_loss: 3.9773 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.2430e-07 - acc: 1.0000 - val_loss: 3.9793 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.2080e-07 - acc: 1.0000 - val_loss: 3.9811 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.1738e-07 - acc: 1.0000 - val_loss: 3.9826 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 3.1403e-07 - acc: 1.0000 - val_loss: 3.9840 - val_acc: 0.8000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.1076e-07 - acc: 1.0000 - val_loss: 3.9852 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.0756e-07 - acc: 1.0000 - val_loss: 3.9863 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.0443e-07 - acc: 1.0000 - val_loss: 3.9872 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 3.0139e-07 - acc: 1.0000 - val_loss: 3.9880 - val_acc: 0.8000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.9842e-07 - acc: 1.0000 - val_loss: 3.9887 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.9553e-07 - acc: 1.0000 - val_loss: 3.9893 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.9271e-07 - acc: 1.0000 - val_loss: 3.9899 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.8997e-07 - acc: 1.0000 - val_loss: 3.9903 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.8730e-07 - acc: 1.0000 - val_loss: 3.9906 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.8471e-07 - acc: 1.0000 - val_loss: 3.9909 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.8218e-07 - acc: 1.0000 - val_loss: 3.9912 - val_acc: 0.8000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.7973e-07 - acc: 1.0000 - val_loss: 3.9914 - val_acc: 0.8000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.7735e-07 - acc: 1.0000 - val_loss: 3.9915 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.7504e-07 - acc: 1.0000 - val_loss: 3.9916 - val_acc: 0.8000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.7279e-07 - acc: 1.0000 - val_loss: 3.9916 - val_acc: 0.8000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.7061e-07 - acc: 1.0000 - val_loss: 3.9917 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.6849e-07 - acc: 1.0000 - val_loss: 3.9917 - val_acc: 0.8000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.6644e-07 - acc: 1.0000 - val_loss: 3.9916 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.6445e-07 - acc: 1.0000 - val_loss: 3.9916 - val_acc: 0.8000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.6251e-07 - acc: 1.0000 - val_loss: 3.9915 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e144c4348>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_datagenerator,\n",
    "    epochs=100,\n",
    "    validation_data = test_datagenerator,\n",
    "    callbacks = [callbacks]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
